# Acceleration-based-action-detection

This project implements a system for real-time detection of user physical actions 
based on acceleration and gyroscope data collected from Android mobile device sensors. 
The app captures raw accelerometer data, processes it, and uses trained machine learning models 
to classify user actions like walking, jogging, dribbling, or clapping.

Features

Real-time sensor data capture from accelerometer and gyroscope.
Data recording and saving as CSV files for offline analysis.
Preprocessing and feature extraction pipelines in Python for time-series sensor data.
Machine learning model training and testing on labeled datasets.
Android app implemented in Kotlin for sensor data acquisition and on-device prediction.